\documentclass{article}
\usepackage{amsmath,amssymb,amsthm,tikz,tkz-graph,color,chngpage,soul,hyperref,csquotes,graphicx,floatrow,listings, mathrsfs,framed,scrextend,mathrsfs,mathtools,setspace}
\usepackage[shortlabels]{enumitem}
\usepackage[nobreak=true]{mdframed}
\usepackage[margin=0.75in]{geometry}
\usetikzlibrary{matrix,calc}\MakeOuterQuote{"}
\renewenvironment{leftbar}[2][\hsize]{
\def\FrameCommand
{
    {\color{#2}\vrule width 3pt}
    \hspace{0pt}
    }
    \MakeFramed{\hsize#1\advance\hsize-\width\FrameRestore}
}
{\endMakeFramed}
\newtheorem*{prop}{Proposition}
\renewcommand{\theenumi}{\alph{enumi}}
\newtheorem{theorem}{Theorem}
\newcommand*{\QEDB}{\hfill\ensuremath{\square}}
\newcommand{\Z}{\mathbb Z}
\newcommand{\R}{\mathbb R}
\newcommand{\Q}{\mathbb Q}
\newcommand{\N}{\mathbb N}
\newcommand{\x}[1]{\textrm{#1}}
\newcommand{\pr}[1]{\textrm{Pr}[#1]}
\newcommand{\xs}[1]{\textrm{ #1 }}
\newcommand{\dpic}[1]{\begin{center}\includegraphics[width=0.5\textwidth]{#1}\end{center}}
\newcommand{\dpicl}[1]{\\\includegraphics[width=0.5\textwidth]{#1}\\}
\newcommand{\tpic}[1]{\begin{center}\includegraphics[width=0.33\textwidth]{#1}\end{center}}
\newcommand{\wpic}[1]{\begin{center}\includegraphics[width=0.8\textwidth]{#1}\end{center}}
\newcommand{\sumlim}[3]{\sum\limits_{#1}^{#2}#3}
\newcommand{\eq}[1]{\begin{equation}#1\end{equation}}
\newcommand{\eqx}[1]{\begin{equation*}#1\end{equation*}}
\newcommand{\w}{\omega}\newcommand{\Om}{\Omega}
\newcommand{\set}[1]{\{#1\}}
\newcommand{\scr}[1]{\mathscr{#1}}
\newcommand{\easy}[2]{\begin{leftbar}{#1}#2\end{leftbar}}
\newcommand{\eqs}[1]{\begin{mdframed}#1\end{mdframed}}
\newcommand{\simple}[1]{\easy{gray}{\begin{enumerate}[1.]#1\end{enumerate}}}
\newcommand{\ex}[1]{\easy{blue}{#1}}
\providecommand{\abs}[1]{\lvert#1\rvert} \providecommand{\norm}[1]{\lVert#1\rVert}
\newcommand{\items}[1]{\begin{itemize}#1\end{itemize}}
\newcommand{\itemss}[2]{\begin{itemize}[#1]#2\end{itemize}}
\newcommand{\rng}[2]{#1,\ldots,#2}
\newcommand{\E}[1]{E[#1]}
\newcommand{\var}[1]{\x{Var}[#1]}
\newcommand{\e}{\varepsilon}
\newcommand{\limty}{\lim_{n\rightarrow\infty}}
\newcommand{\ninfty}{n\rightarrow\infty}
\newcommand{\cov}{\x{cov}}
\newmdenv[topline=false, rightline=false, bottomline=false,%
  linewidth=3pt, innerrightmargin=0pt, leftmargin=4pt,%
  innerleftmargin=5pt, skipabove=5pt, skipbelow=5pt]{mdleftbar}
\newcommand{\example}[2]{\textbf{Example: }\\#1\begin{mdleftbar}\onehalfspacing{#2}\end{mdleftbar}}
\newcommand{\cur}{\mathscr}
\newcommand{\bmat}[1]{\begin{bmatrix*}[r]#1\end{bmatrix*}}
\newcommand{\bmatc}[1]{\begin{bmatrix*}[c]#1\end{bmatrix*}}
\newcommand{\bmats}[2]{\begin{bmatrix}[#1]#2\end{bmatrix}}
\newcommand{\case}[2]{\eq{#1=\begin{cases}#2\end{cases}}}
\newcommand{\intlim}[2]{\int_{#1}^{#2}}

\title{CS70 - Lecture 26 Notes}
\author{Name: Felix Su$\quad$SID: 25794773}
\date{Spring 2016$\quad$GSI: Gerald Zhang}
\begin{document}
\maketitle

%%%% Topic %%%%
\subsection*{Continuous Probability}
%%%% Notes %%%%
\simple{
    \item Use \textbf{unions of intervals} to describe events
}
\items{
    \item Choose a real number $X$, uniformly at random in [0,L].
    \item Let [a,b] denote the event that the point $X$ is in the interval [a,b].
    \items{
        \item $\pr{[a,b]} =\frac{\x{length of } [a,b]}{\x{length of } [0,L]}=\frac{b-a}{L}=\frac{b-a}{1000}$
    }
    \item Events in this space are unions of intervals.
    \item \textbf{Example:} the event A - “within 50 of 0 or 1000” is
    \items{
        \item $A = [0,50] \cup [950,1000]$. Thus, $\pr{A} = \pr{[0,50]} +\pr{[950,1000]} =\frac{1}{10}$
    }
}
\textbf{Finite vs. Continuous Probability Spaces}
\simple{
	\item Start with probability of events (unions of intervals): $\pr{A}$ for some events $A$
	\item Probability is then a function from events to [0,1]
	\item Function must be additive
}
\items{
	\item \textbf{Finite probability space:} $\Omega = \set{1,2,\ldots,N}$
	\items{
		\item Started with probabilities of each outcome $\pr{\omega} = p_\omega$
		\item Defined probability of event is sum of probability of outcomes in the event: $\pr{A} = \sumlim{\omega \in A}{}{p\omega}$ for $A \subset \Omega$.
		\item We used the same approach for countable $\Omega$.
	}
	\item \textbf{Continuous space:} $\Omega = [0,L],$
	\items{
		\item Cannot start with $\pr{\Omega}$, because this will typically be 0.
		\item Start with probability of events (unions of intervals): $\pr{A}$ for some events $A$. Here, we started with $A$ = interval, or union of intervals.
		\item Probability is then a function from events to [0,1]
		\item Function must be additive. In our example, $\pr{[0,50]\cup[950,1000]} = \pr{[0,50]} +\pr{[950,1000]}$
	}
}
\example{James Bond Shooting}{
Chance of landing in a one foot radius circle that is inside a $4\times5$ rectangle.\\
$\Omega = \set{(x,y) : x \in [0,4],y \in [0,5]}$.\\
The size of the event is $\pi(1)^2 = \pi$.\\
The "size" of the sample space which is $4\times5$.\\
Since uniform, probability of event is $\frac{\pi}{20}$.
}
\subsection*{Continuous Random Variables: CDF}
\simple{
	\item Define $\pr{a < X \le b} = \pr{X \le b}-\pr{X \le a} = F_X(b)-F_X(a)$
}
\items{
	\item Find function to define all intervals between $a$ and $b$: $\pr{a < X \le b}$
	\item Cumulative probability Distribution Function of $X$ (CDF of $X$) is
	\items{
		\item $F_X(x) = \pr{X \le x}$
	}
	\item So, $\pr{a < X \le b} = \pr{X \le b}-\pr{X \le a} = F_X(b)-F_X(a)$.
	\items{
		\item Idea: two events $X \le b$ and $X \le a$.
		\item Difference is the event $a < X \le b$.
		\item Indeed: $\set{X \le b} - \set{X \le a} = \set{X \le b} \cap \set{X > a} = \set{a < X \le b}$.
	}
}
\eqs{
\textbf{Cumulative Probability Distribution Function of $X$: CDF}
\eq{F_X(x) = \pr{X \le x}}
\textbf{Define Probability of all Intervals}
\eq{\pr{a < X \le b} = \pr{X \le b}-\pr{X \le a} = F_X(b)-F_X(a)}
}
\example{
CDF: Value of X in [0,L] with L = 1000.
\case{F_X (x) = \pr{X \le x}}{0 &\mbox{for } x < 0\\ \frac{x}{1000} & \mbox{for } 0 \le x \le 1000 \\1 &\mbox{for } x > 1000}
}{
Probability that $X$ is within 50 of center:\\
$\pr{450 < X \le 550} = \pr{X \le 550}-\pr{X \le 450}=\frac{550}{1000}-\frac{450}{1000}=\frac{100}{1000}=\frac{1}{10}$
}
\example{CDF: Hitting random location on a unit circle.
\tpic{gt}
Random Variable: $Y$ distance from center.\\
}{
Probability within $y$ of center:\\
\eq{\pr{Y \le y} =\frac{\x{area of small circle}}{\x{area of dartboard}}=\frac{\pi y^2}{\pi}= y^2}
Hence,
\case{F_Y (y) = \pr{Y \le y}}{0 &\mbox{for } y < 0\\ y^2&\mbox{for } 0 \le y \le 1\\1&\mbox{for } y > 1}
\textbf{Calculation} Probability between .5 and .6 of center\\
$\pr{0.5 < Y \le 0.6} = \pr{Y \le 0.6}-\pr{Y \le 0.5}= F_Y (0.6)-F_Y (0.5)= .36-.25= .11$
}
\subsection*{Density function}
\simple{
    \item Find probability of a certain value (within $\delta$): $\lim_{\delta \rightarrow 0}\frac{\pr{x < X \le x +\delta}}{\delta} = \frac{d(F_X (x))}{dx}$
}
\items{
	\item Is the dart more like to be (near) .5 or .1?
	\item Probability within $\delta$ of $x$ is $\pr{x < X \le x +\delta}$.
	\item Goes to 0 as $\delta$ goes to zero.
	\item Find the limit as $\delta$ goes to zero. $\lim_{\delta \rightarrow 0}\frac{\pr{x < X \le x +\delta}}{\delta}$
	\itemss{*}{
	    \item $=\lim_{\delta\rightarrow 0}\frac{\pr{X \le x +\delta}-\pr{X \le x}}{\delta}$
	    \item $= \lim_{\delta\rightarrow 0}\frac{F_X (x +\delta)-F_X (x)}{\delta}$
	    \item $=\frac{d(F_X (x))}{dx}$
	}
}
\subsection*{Density}
\simple{
    \item A \textbf{probability density function} for RV $X$ with cdf $F_X(x)=\pr{X \le x}$ is the derivate of the cdf: $f_X(x)=\frac{d(F_X (x))}{dx}$
    \item Probability that $X$ is within $\delta$ of $x$, is $f_X (x)\delta$
}
\items{
    \item Definition: (Density) A probability density function for a random variable $X$ with cdf $F_X(x) = \pr{X \le x}$ is the function $f_X (x)$ where:
    \eq{F_X (x) = \intlim{-\infty}{x}f_X (u)du}
    \item Thus, $\pr{X \in (x,x +\delta]} = F_X (x +\delta)-F_X (x) \approx f_X (x)\delta$
}
\eqs{
\textbf{Probability Density Function}\\
For random variable $X$ with cdf $F_X(x) = \pr{X \le x}$ is the function $f_X (x)$ where:
\eq{\pr{X \in (x,x +\delta]} = F_X (x +\delta)-F_X (x) \approx f_X (x)\delta}
}
\example{Uniform over interval [0,1000]}{
\case{f_X (x) = F_X(x)}{0 & \mbox{for } x < 0\\\frac{1}{1000} & \mbox{for } 0 \le x \le 1000\\0 & \mbox{for } x > 1000}
}
\example{Uniform over interval [0,L]}{
\case{f_X (x) = F_X(x)}{0 & \mbox{for } x < 0\\\frac{1}{L} & \mbox{for } 0 \le x \le L\\0 & \mbox{for } x > L}
}
\example{"Dart" board\\
\items{
	\item The cumulative distribution function (cdf) and probability distribution function (pdf) give full information.
	\item Use whichever is convenient.
}}{
\case{F_Y(y) = \pr{Y \le y}}{0 &\mbox{for } y < 0\\y^2&\mbox{for } 0 \le y \le 1\\1&\mbox{for }y > 1}
\case{f_Y (y) = F'_Y(y)}{0&\mbox{for }y < 0\\2y&\mbox{for }0 \le y \le 1\\0&\mbox{for }y > 1}
}
\textbf{Target}
\dpic{target}
\textbf{Uniform Distribution: U[a,b]}
\dpic{uniform}
\textbf{Expo($\lambda$)}
\items{
	\item Note that $\pr{X > t} = e^{-\lambda t}\xs{for} t > 0$
}
\dpic{expo}
\eqs{
The exponential distribution with parameter $\lambda > 0$ is defined by
\eq{f_X (x) = \lambda e^{-\lambda x}1\set{x \ge 0}}
\case{F_X (x)}{0&\mbox{if } x < 0\\1-e^{-\lambda x}&\mbox{if } x \ge 0}
}
\subsection*{Random Variables}
\dpic{pic}
\textbf{Continuous random variable $X$, specified by}
\begin{enumerate}[1.]
	\item $F_X (x) = \pr{X \le x}, \forall x$
	\items{
		\item \textbf{Cumulative Distribution Function (cdf)}: $\pr{a < X \le b} = F_X (b)-F_X (a)$
		\item Non-decreasing between 0 and 1
		\items{
			\item $0 \le F_X (x) \le 1 \forall x \in \R$.
			\item $F_X (x) \le F_X (y) \xs{if} x \le y$.
		}
	}
	\item Or $f_X (x)$ , where $F_X (x) =\intlim{-\infty}{x}f_X (u)du$ or $f_X (x) =\frac{d(F_X (x))}{dx}$
	\items{
		\item \textbf{Probability Density Function (pdf)}: $\pr{a < X \le b} =\intlim{a}{b}f_X (x)dx = F_X (b)-F_X (a)$
		\item Non-negative and integrates to 1.
		\items{
			\item $f_X (x) \ge 0 \forall x \in \R$.
			\item $\intlim{-\infty}{\infty}f_X (x)dx = 1$
		}
	}
	\item Recall that $\pr{X \in (x,x +\delta)} \approx f_X (x)\delta$.
	\items{
		\item Probability that you are $\delta$ away from $x$ is $\approx f_X (x)\delta$
		\item If density ($f_X (x)$) is large, more likely to be at $x$.
	}
	\item Think of $X$ taking discrete values $n\delta$ for $n = \ldots,-2,-1,0,1,2,\ldots$ with $\pr{X = n\delta} = f_X (n\delta)\delta$
\end{enumerate}
\textbf{Some Examples}
\begin{enumerate}
	\item  \textbf{Expo is memoryless}. Let $X = $Expo($\lambda$). Then, for $s,t > 0$
	\items{
		\item $\pr{X > t +s | X > s} =\frac{\pr{X > t +s}}{\pr{X > s}}=\frac{e^{-\lambda(t+s)}}{e^{-\lambda s}} = e^{-\lambda t}= \pr{X > t}$.
		\item 'Used is a good as new.'
	}
	\item \textbf{Scaling Expo}. Let $X = $Expo($\lambda$) and $Y = aX$ for some $a > 0$. Then
	\items{
		\item $\pr{Y > t} = \pr{aX > t} = \pr{X > t/a}= e^{-\lambda(t/a)} = e^{-(\lambda /a)t} = \pr{Z > t}$ for $Z = $Expo($\lambda/a$)
		\item Thus, $a\times$ Expo($\lambda$) = Expo($\lambda /a$).
	}
	\item \textbf{Scaling Uniform} Let $X = U[0,1]$ and $Y = a+bX$ where $b > 0$. Then
	\items{
		\item $\pr{Y \in (y,y +\delta)} = \pr{a+bX \in (y,y +\delta)} = \pr{X \in (\frac{y-a}{b},\frac{y +\delta-a}{b})}$
		\items{
			\item $= \pr{X \in (\frac{y-a}{b},\frac{y-a}{b}+\frac{\delta}{b})} =\frac{1}{b}\delta$, for $0 <\frac{y-a}{b}< 1$
			\item $=\frac{1}{b}{\delta}$, for $a < y < a+b$.
		}
		\item Thus, $f_Y (y) = \frac{1}{b}$ for $a < y < a+b$. Hence, $Y = U[a,a+b]$.
	}
	\item \textbf{Scaling pdf}. Let $f_X (x)$ be the pdf of $X$ and $Y = a+bX$ where $b > 0$. Then
	\items{
		\item $\pr{Y \in (y,y +\delta)} = \pr{a+bX \in (y,y +\delta)}$
		\items{
			\item $= \pr{X \in (\frac{y-a}{b},\frac{y +\delta-a}{b}}$
			\item $= \pr{X \in (\frac{y-a}{b},\frac{y-a}{b}+\frac{\delta}{b}}$
			\item $= f_X (\frac{y-a}{b})\frac{\delta}{b}$
		}
		\item Now, the left-hand side is $f_Y (y)\delta$. Hence, $f_Y (y) =\frac{1}{b}f_X (\frac{y-a}{b})$.
	}
\end{enumerate}
\subsection*{Expectation}
\items{
	\item \textbf{Definition} The expectation of a random variable $X$ with pdf $f_X(x)$ is defined as $\E{X} =\intlim{-\infty}{\infty}xf_X (x)dx$.
	\item Justification: Say $X = n\delta$ w.p. $f_X (n\delta)\delta$. Then,
	\items{
		\item	$\E{X} = \sumlim{n}{}{(n\delta)\pr{X = n\delta}} = \sumlim{n}{}{(n\delta)f_X (n\delta)\delta} =\intlim{-\infty}{\infty}xf_X (x)dx$.
	}
	\item Indeed, for any $g$, one has $\int g(x)dx \approx \sumlim{n}{}{g(n\delta)\delta}$. Choose $g(x) = xf_X (x)$.
}
\subsection*{Expectation of function of RV}
\items{
	\item \textbf{Definition} The expectation of a function of a random variable is defined as $\E{h(X)} =\intlim{-\infty}{\infty}h(x)f_X (x)dx$.
	\item Justification: Say $X = n\delta$ w.p. $f_X (n\delta)\delta$. Then
	\items{
		\item $\E{h(X)} = \sumlim{n}{}{h(n\delta)\pr{X = n\delta}}$
		\item $= \sumlim{n}{}{h(n\delta)f_X (n\delta)\delta}$
		\item $= \intlim{-\infty}{\infty}h(x)f_X (x)dx$.
	}
	\item Indeed, for any $g$, one has $\int g(x)dx \approx \sumlim{n}{}{g(n\delta)\delta}$. Choose $g(x) = h(x)f_X (x)$.
	\item \textbf{Fact} Expectation is linear.
	\item \textbf{Proof} As in the discrete case.
}
\eqs{
\textbf{$\E{X}$ with pdf $f_X(x)$}
\eq{\E{X} =\intlim{-\infty}{\infty}xf_X (x)dx}
\textbf{Exepection of a function of RV $X$: $\E{h(X)}$ with pdf $f_X(x)$}
\eq{\E{h(X)} =\intlim{-\infty}{\infty}h(x)f_X (x)dx}
}
\subsection*{Variance}
\items{
	\item \textbf{Definition:} The variance of a continuous random variable X is defined as $\var{X} = \E{(X-\E{X})^2} = \E{X^2}-(\E{X})^2= \intlim{-\infty}{\infty}x^2f(x)dx-(\intlim{-\infty}{\infty}xf(x)dx)^2$
}

\eqs{
\textbf{Variance}
\eq{\var{X} =\intlim{-\infty}{\infty}x^2f(x)dx-(\intlim{-\infty}{\infty}xf(x)dx)^2}
}
\subsection*{Motivation for Gaussian Distribution}
\items{
	\item \textbf{Key fact:} The sum of many small independent RVs has a Gaussian distribution.
	\item This is the Central Limit Theorem. (See later.)
	\item Examples: Binomial and Poisson suitably scaled.
	\item This explains why the Gaussian distribution (the bell curve) shows up everywhere.
}
\subsection*{Normal Distribution}
\tpic{gauss}
\items{
	\item For any mean: $\mu$ and std. dev: $\sigma$, a \textbf{normal} (aka \textbf{Gaussian}) random variable $Y$, which we write as $Y = \cur{N}(\mu,\sigma^2)$, has pdf $f_Y (y) = \frac{1}{\sqrt{2\pi\sigma^2}}e^{-(y-\mu)^2/2\sigma^2}$
	\item Standard normal has $\mu = 0$ and $\sigma = 1$.
	\item Note: $\pr{\abs{Y - \mu} > 1.65\sigma} = 10\%$;$\pr{\abs{Y - \mu} > 2\sigma} = 5\%$.
	\item Guassian RV is within $2\sigma$ of the mean with $95\%$
}
\eqs{
\textbf{Normal Distribution}\\
For any $\mu$ and $\sigma$, a Gaussian RV, $Y = \cur{N}(\mu,\sigma^2)$ has pdf:
\eq{f_Y (y) = \dfrac{1}{\sqrt{2\pi\sigma^2}}e^{-(y-\mu)^2/2\sigma^2}}
}
\subsection*{Summary: Continuous Probability}
\simple{
	\item \textbf{pdf}: $\pr{X \in (x,x +\delta]} = f_X (x)\delta$.
	\item \textbf{CDF}: $\pr{X \le x} = F_X (x) =\intlim{-\infty}{x}f_X (y)dy$.
	\item \textbf{U[a,b], Expo($\lambda$), target}
	\item \textbf{Expectation}: $\E{X} =\intlim{-\infty}{\infty}xf_X (x)dx$.
	\item \textbf{Expectation of function}: $\E{h(X)} =\intlim{-\infty}{\infty}h(x)f_X (x)dx$.
	\item \textbf{Variance}: $\var{X} = \E{(X-\E{X})^2} = \E{X^2}-\E{X}^2$.
	\item \textbf{Gaussian}: $N (\mu,\sigma^2) : f_X (x) = \ldots$ "bell curve"
}
\end{document}